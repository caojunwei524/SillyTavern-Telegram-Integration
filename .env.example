# SillyTavern Telegram Integration v2.0 - Environment Variables
# Copy this file to .env and fill in the values

# ===========================================
# REQUIRED: Telegram Bot Configuration
# ===========================================

# Your Telegram Bot Token (get from @BotFather)
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Your Telegram User ID for authorization (get from @userinfobot)
# Set to 0 to allow all users (not recommended for production)
ALLOWED_USER_ID=123456789

# ===========================================
# OPTIONAL: Multi-user authorization (bot layer)
# ===========================================

# Persistent auth database path inside container (mounted via docker-compose volume)
TG_AUTH_DB_PATH=/app/data/auth.json

# Allow users to request/register by default (admin can toggle via /registration)
TG_REGISTRATION_ENABLED=1

# ===========================================
# OPTIONAL: Performance (multi-user)
# ===========================================

# Max number of Telegram updates processed concurrently
TG_CONCURRENT_UPDATES=8

# Telegram Bot API HTTP connection pool size
TG_CONNECTION_POOL_SIZE=64

# Seconds to wait for a free connection from the pool
TG_POOL_TIMEOUT=30

# ===========================================
# OPTIONAL: Telegram streaming / typing
# ===========================================

# Enable "typing..." and progressive message edits (requires plugin streaming endpoint)
# 1=true, 0=false
TELEGRAM_STREAM_RESPONSES=1

# How often to edit the in-progress message (ms)
TELEGRAM_STREAM_EDIT_INTERVAL_MS=750

# How often to send chat action "typing" (ms)
TELEGRAM_TYPING_INTERVAL_MS=3500

# Placeholder message shown before any tokens arrive
TELEGRAM_STREAM_PLACEHOLDER=输入中...

# ===========================================
# REQUIRED: LLM API Configuration
# ===========================================

# LLM API URL (OpenAI-compatible endpoint)
# Default: https://api.openai.com/v1
# Examples:
#   - OpenRouter: https://openrouter.ai/api/v1
#   - Azure: https://YOUR_RESOURCE.openai.azure.com
#   - Local: http://localhost:5001/v1
LLM_API_URL=https://api.openai.com/v1

# LLM API Key (REQUIRED)
LLM_API_KEY=your_openai_api_key_here

# LLM Model name
# OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo
# OpenRouter: anthropic/claude-3-sonnet, etc.
LLM_MODEL=gpt-4o-mini

# Maximum tokens for AI response
LLM_MAX_TOKENS=2048

# Temperature (0.0-2.0, higher = more creative)
LLM_TEMPERATURE=0.9

# ===========================================
# OPTIONAL: Default Preset
# ===========================================

# Default preset name (must exist in data/default-user/OpenAI Settings/)
# If not found, uses built-in defaults
PRESET_NAME=Default

# ===========================================
# OPTIONAL: Context Configuration
# ===========================================

# Maximum context size (tokens) for conversation history
CONTEXT_SIZE=8192

# Default World Info / Lorebook name (optional)
# Must exist in data/default-user/worlds/
DEFAULT_WORLD_INFO=

# ===========================================
# OPTIONAL: Webhook Configuration
# ===========================================

# Webhook URL (required for production deployment)
# Leave empty to use polling mode (for testing)
WEBHOOK_URL=

# ===========================================
# OPTIONAL: Logging
# ===========================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ===========================================
# OPTIONAL: SillyTavern Basic Auth
# ===========================================

# If you enable basicAuthMode in config.yaml, set the same credentials here
# This allows the Bot to access SillyTavern API with authentication
ST_AUTH_USER=admin
ST_AUTH_PASS=your_password_here
